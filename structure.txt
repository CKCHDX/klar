klar/
├── api/                           # FastAPI backend (search API)
│   ├── __init__.py
│   ├── main.py                    # API entry point
│   ├── models.py                  # Pydantic models
│   └── routes.py                  # API routes and logic
│
├── crawler/                       # Web crawler
│   ├── __init__.py
│   ├── crawl.py                   # Starts crawling process
│   ├── parser.py                  # HTML/content parsing
│   └── utils.py                   # Helpers for crawling
│
├── search_index/                 # Search engine indexer
│   ├── __init__.py
│   ├── client.py                  # Connect to search engine
│   └── indexer.py                 # Index documents
│
├── frontend/                      # Static web UI
│   ├── index.html                 # Main search page
│   ├── results.html               # Results page (optional)
│   ├── style.css                  # Minimal CSS styling
│   └── app.js                     # JS logic to call API
│
├── config/                        # Configs and seed files
│   ├── config.yaml                # Global configuration
│   └── domains.txt                # Swedish domains to crawl
│
├── data/                          # Local data (crawled, cleaned)
│   ├── raw/                       # Raw crawled content
│   └── cleaned/                   # Cleaned & parsed data
│
├── logs/                          # Log files
│   └── crawler.log
│
├── scripts/                       # Utility scripts
│   ├── start_local.sh             # Start local services
│   └── test_query.py              # Manual API test script
│
├── .env                           # Environment variables (API keys, ports, etc.)
├── LICENSE                        # License (e.g., MIT)
├── README.md                      # Project documentation
└── requirements.txt               # Python dependencies

packages

fastapi               # Backend API
uvicorn               # ASGI server for FastAPI
scrapy                # Web crawler framework
beautifulsoup4        # HTML parsing
typesense             # Search engine client (or use Elasticsearch)
requests              # For HTTP requests
pydantic              # For data validation
python-dotenv         # Load env vars from .env
lxml                  # Fast HTML/XML parsing
